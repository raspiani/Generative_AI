{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1. Initialize Vertex AI in a Colab Enterprise notebook"
      ],
      "metadata": {
        "id": "7Ywsi6-UHbrn"
      },
      "id": "7Ywsi6-UHbrn"
    },
    {
      "cell_type": "code",
      "id": "LjWrjj6LcC1B5wbRT496c2rh",
      "metadata": {
        "tags": [],
        "id": "LjWrjj6LcC1B5wbRT496c2rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125457918,
          "user_tz": -420,
          "elapsed": 21829,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2a66cdb8-0a95-4b87-e587-7add25286a38"
      },
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ],
      "metadata": {
        "id": "K2spqU9SG72v",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125469364,
          "user_tz": -420,
          "elapsed": 5324,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "K2spqU9SG72v",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-03-f47a071679ee\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "G9aSUOyRHkD-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125491042,
          "user_tz": -420,
          "elapsed": 2593,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "G9aSUOyRHkD-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2. Load a generative model"
      ],
      "metadata": {
        "id": "nNjUVfDtHsal"
      },
      "id": "nNjUVfDtHsal"
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "K6BxCnk-Hp72",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125509339,
          "user_tz": -420,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "K6BxCnk-Hp72",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3. Define the output format & specify constraints"
      ],
      "metadata": {
        "id": "bnBtickTHxs1"
      },
      "id": "bnBtickTHxs1"
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "    Speaker 1 (Customer): Hi, can I get a cheeseburger and large fries, please?\n",
        "    Speaker 2 (Restaurant employee): Coming right up! Anything else you'd like to add to your order?\n",
        "    Speaker 1: Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\n",
        "    Speaker 2: No problem, one cheeseburger, one large fries with ketchup on the side, and a small\n",
        "    orange juice. That'll be $5.87. Drive through to the next window please.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q_A2FdlhHuiF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125535669,
          "user_tz": -420,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "Q_A2FdlhHuiF",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    Extract the transcript to JSON.\n",
        "\n",
        "    {transcript}\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwL0zwNpH09_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125554056,
          "user_tz": -420,
          "elapsed": 2613,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6c1c10df-dce0-44e0-d791-aab3a8bfac90"
      },
      "id": "NwL0zwNpH09_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "{\n",
            "  \"turns\": [\n",
            "    {\n",
            "      \"speaker\": \"Customer\",\n",
            "      \"utterance\": \"Hi, can I get a cheeseburger and large fries, please?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Restaurant employee\",\n",
            "      \"utterance\": \"Coming right up! Anything else you'd like to add to your order?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Customer\",\n",
            "      \"utterance\": \"Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\"\n",
            "    },\n",
            "    {\n",
            "      \"speaker\": \"Restaurant employee\",\n",
            "      \"utterance\": \"No problem, one cheeseburger, one large fries with ketchup on the side, and a small orange juice. That'll be $5.87. Drive through to the next window please.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    <INSTRUCTIONS>\n",
        "    - Extract the ordered items into JSON.\n",
        "    - Separate drinks from food.\n",
        "    - Include a quantity for each item and a size if specified.\n",
        "    </INSTRUCTIONS>\n",
        "\n",
        "    <TRANSCRIPT>\n",
        "    {transcript}\n",
        "    </TRANSCRIPT>\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n566IVbQH49h",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125574805,
          "user_tz": -420,
          "elapsed": 2698,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8fc944af-4e0f-4e46-a833-fa5132e0dc4b"
      },
      "id": "n566IVbQH49h",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"food\": [\n",
            "    {\n",
            "      \"item\": \"cheeseburger\",\n",
            "      \"quantity\": 1\n",
            "    }\n",
            "  ],\n",
            "  \"drinks\": [\n",
            "    {\n",
            "      \"item\": \"orange juice\",\n",
            "      \"size\": \"small\",\n",
            "      \"quantity\": 1\n",
            "    }\n",
            "  ],\n",
            "  \"other\": [\n",
            "    {\n",
            "      \"item\": \"fries\",\n",
            "      \"size\": \"large\",\n",
            "      \"quantity\": 1,\n",
            "      \"modifier\": \"ketchup on the side\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4. Assign a persona or role"
      ],
      "metadata": {
        "id": "LAb4ewyjIEuB"
      },
      "id": "LAb4ewyjIEuB"
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "154Lt2bNH-TN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125616965,
          "user_tz": -420,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "154Lt2bNH-TN",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"\"\"\n",
        "    Provide a brief guide to caring for the houseplant monstera deliciosa?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4D8WRzYIIjP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125632611,
          "user_tz": -420,
          "elapsed": 6892,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "caf08ffe-c341-4f6c-8fd6-2fc1c181c9f1"
      },
      "id": "E4D8WRzYIIjP",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Monstera Deliciosa Care Guide: \n",
            "\n",
            "**Light:** Your Monstera will thrive in bright, indirect light. Avoid direct sun, which can scorch its leaves. East-facing windows are ideal. \n",
            "\n",
            "**Watering:** Allow the top inch of soil to dry out before watering. Overwatering is a common killer of Monsteras. Water deeply, ensuring excess drains through the pot. During winter, water less frequently. \n",
            "\n",
            "**Humidity:** Aim for a humidity level between 60-80%. Grouping plants, using a pebble tray, or a humidifier can increase humidity. Misting the leaves occasionally can also help. \n",
            "\n",
            "**Fertilizer:** Feed your Monstera with a balanced, diluted liquid fertilizer monthly during spring and summer. Avoid fertilizing during fall and winter. \n",
            "\n",
            "**Support:** As Monsteras grow taller, they require support. Provide a moss pole or wooden stake for your plant to climb, encouraging healthy growth. \n",
            "\n",
            "**Pruning:** Pruning helps maintain your Monstera's size and shape and encourages branching. Using sharp, sterilized shears, trim stems just above a node.\n",
            "\n",
            "**Soil:** Use a well-draining, slightly acidic potting mix. You can also mix in coco coir, perlite, or orchid bark for additional drainage. \n",
            "\n",
            "**Repotting:** Repot your Monstera every year or two as it grows. Choose a pot slightly larger than the previous one with drainage holes. \n",
            "\n",
            "**Toxicity:** All parts of the Monstera deliciosa are toxic to humans and pets if ingested. Keep it out of reach of children and animals. \n",
            "\n",
            "**Common problems:** Watch for signs of pests or diseases such as spider mites, scale, and root rot. Treat promptly with appropriate solutions. \n",
            "\n",
            "**Enjoying your Monstera:** With proper care, your Monstera will reward you with its lush green foliage and beautiful split leaves. Remember, patience is key, as these plants are slow growers.  \n",
            "\n",
            "**Additional resources:** \n",
            "\n",
            "* https://www.thesill.com/blog/monstera-plant-care\n",
            "* https://www.bhg.com/gardening/houseplants/care/how-to-grow-monstera/\n",
            "* https://www.costafarms.com/plants/monstera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chat = model.start_chat()\n",
        "\n",
        "response = new_chat.send_message(\n",
        "    \"\"\"\n",
        "    You are a houseplant monstera deliciosa. Help the person who\n",
        "    is taking care of you to understand your needs.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8n1WcaFILSg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125654268,
          "user_tz": -420,
          "elapsed": 6449,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "63cdec71-bdf0-48e1-cb52-c1800b2916bf"
      },
      "id": "w8n1WcaFILSg",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey there! It's me, your Monstera deliciosa, also known as the Swiss cheese plant! I appreciate you taking care of me, and I want to help you understand what I need to thrive in your loving home. \n",
            "\n",
            "Here's a quick peek into the life of a happy Monstera:\n",
            "\n",
            "**Light:** I'm a sun-loving gal, but I'm not a fan of harsh, direct sunlight. Think of me like Goldilocks; I prefer **bright, indirect light**. A spot near a window that gets filtered sunshine would be perfect!\n",
            "\n",
            "**Watering:** Don't let my large, lush leaves fool you! I prefer my soil to be slightly dry between waterings. Think \"damp\" rather than \"soggy.\" In the summer, I might need a drink every week or so, but during winter, I can wait a bit longer. Feel free to stick your finger in the soil to check the moisture level before giving me a drink.\n",
            "\n",
            "**Humidity:** My tropical roots crave humidity. If the air feels a bit dry, especially during winter, consider using a humidifier or grouping me with other plants to increase the humidity around me. \n",
            "\n",
            "**Food:** Like any growing creature, I need some nourishment. During spring and summer, a monthly dose of liquid fertilizer diluted to half strength would keep me happy and growing strong.\n",
            "\n",
            "**Support:** As I climb towards the sky, I need some support to stay upright. A moss pole or a trellis would be greatly appreciated! I'll happily hug it and climb upwards, adding a touch of jungle vibes to your space.\n",
            "\n",
            "**Pests and diseases:** Keep an eye out for common houseplant pests like mealybugs and spider mites. If you spot any, address them promptly with insecticidal soap or neem oil. And remember, overwatering can lead to root rot, so always check the soil moisture before watering.\n",
            "\n",
            "By following these simple tips, you'll help me, your Monstera deliciosa, thrive in your home. In return, I'll reward you with my stunning, split leaves and a touch of tropical charm. Remember, happy plant, happy life!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5. Include examples"
      ],
      "metadata": {
        "id": "SRGB7xsGIbVa"
      },
      "id": "SRGB7xsGIbVa"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "We offer software consulting services. Read a potential\n",
        "customer's message and rank them on a scale of 1 to 3\n",
        "based on whether they seem likely to hire us for our\n",
        "developer services within the next month. Return the likelihood\n",
        "rating labeled as \"Likelihood: SCORE\".\n",
        "Do not include any Markdown styling.\n",
        "\n",
        "1 means they are not likely to hire.\n",
        "2 means they might hire, but they are not likely ready to do\n",
        "so right away.\n",
        "3 means they are looking to start a project soon.\n",
        "\n",
        "Example Message: Hey there I had an idea for an app,\n",
        "and I have no idea what it would cost to build it.\n",
        "Can you give me a rough ballpark?\n",
        "Likelihood: 1\n",
        "\n",
        "Example Message: My department has been using a vendor for\n",
        "our development, and we are interested in exploring other\n",
        "options. Do you have time for a discussion around your\n",
        "services?\n",
        "Likelihood: 2\n",
        "\n",
        "Example Message: I have mockups drawn for an app and a budget\n",
        "allocated. We are interested in moving forward to have a\n",
        "proof of concept built within 2 months, with plans to develop\n",
        "it further in the following quarter.\n",
        "Likelihood: 3\n",
        "\n",
        "Customer Message: Our department needs a custom gen AI solution.\n",
        "We have a budget to explore our idea. Do you have capacity\n",
        "to get started on something soon?\n",
        "Likelihood: \"\"\"\n",
        "\n",
        "response = model.generate_content(question)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZl8E5PIQl5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125734501,
          "user_tz": -420,
          "elapsed": 2663,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1a30c178-963c-46c3-8969-66f6b5bf4743"
      },
      "id": "OZZl8E5PIQl5",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Customer Message Analysis:\n",
            "\n",
            "**Message:** Our department needs a custom gen AI solution. We have a budget to explore our idea. Do you have capacity to get started on something soon?\n",
            "\n",
            "**Likelihood:** 3\n",
            "\n",
            "**Explanation:** \n",
            "\n",
            "This message indicates a high likelihood that the customer is ready to move forward with their project. They have already:\n",
            "\n",
            "* Identified a need for a custom AI solution.\n",
            "* Allocated a budget for exploration and development. \n",
            "* Expressed urgency by inquiring about the availability to start soon.\n",
            "\n",
            "These factors suggest that the customer is serious about their project and is likely to hire a developer within the next month, especially if the consulting service can demonstrate the capacity to take on the project promptly. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 6. Experiment with parameter values"
      ],
      "metadata": {
        "id": "QIZP1iwUIxuU"
      },
      "id": "QIZP1iwUIxuU"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .05,\n",
        "                       \"temperature\": 0.05}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIpl17cDIla-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125794026,
          "user_tz": -420,
          "elapsed": 10,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b063286e-e723-4de4-a663-957154a5ffc9"
      },
      "id": "aIpl17cDIla-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog get sent to the principal's office?\n",
            "\n",
            "Because he was caught skipping class! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .98,\n",
        "                       \"temperature\": 1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_9vrMZlI0N7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125802956,
          "user_tz": -420,
          "elapsed": 9,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3db414be-f06b-4ed4-9215-69a7226c2176"
      },
      "id": "B_9vrMZlI0N7",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog get kicked out of the band? \\\n",
            "\\\n",
            "Because he was always croaking the same tune.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 7. Utilize fallback responses"
      ],
      "metadata": {
        "id": "GvQODWQnJEuC"
      },
      "id": "GvQODWQnJEuC"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: How high can a horse jump?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmZRn3HzI2cC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125896502,
          "user_tz": -420,
          "elapsed": 2679,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "432194d1-012d-4df3-95a5-0f6bd86ef803"
      },
      "id": "fmZRn3HzI2cC",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I only talk about pottery! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: What is the difference between ceramic\n",
        "    and porcelain? Please keep your response brief.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqETXWSzJMWS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731125946115,
          "user_tz": -420,
          "elapsed": 2692,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2023b449-cd0b-4d2d-9eac-31eb591e3bd9"
      },
      "id": "CqETXWSzJMWS",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ceramics are made from clay, whereas porcelain requires the addition of other materials, such as feldspar and quartz. This makes porcelain stronger, whiter, and more heat-resistant than ceramics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 8. Add contextual information"
      ],
      "metadata": {
        "id": "Pca47LEEJto5"
      },
      "id": "Pca47LEEJto5"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1EBmAJOJYpm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126052284,
          "user_tz": -420,
          "elapsed": 2674,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "008b7ef3-1d6e-49b3-bcc0-67c096180d23"
      },
      "id": "E1EBmAJOJYpm",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The location of items in a grocery store can vary depending on the specific store layout. However, here's a general guide to help you find the items you listed:\n",
            "\n",
            "* **Paper plates:** Look for paper plates in the **paper goods aisle**, which is typically located near the **disposable cups and napkins**. \n",
            "* **Mustard:** Mustard is usually found in the **condiment aisle**, which is often located near the **pickles and relishes**. You may also find it in the **international aisle** if you're looking for specific types of mustard, such as Dijon or Chinese mustard.\n",
            "* **Potatoes:** Potatoes are usually found in the **produce section**, often near other root vegetables like carrots and onions. They may also be located in a **separate bin** near the **fresh fruit** section.\n",
            "\n",
            "If you're having trouble finding something, don't hesitate to ask a store employee for assistance. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"\"\"\n",
        "    Context:\n",
        "    Michael's Grocery Store Aisle Layout:\n",
        "    Aisle 1: Fruits — Apples, bananas,  grapes, oranges, strawberries, avocados, peaches, etc.\n",
        "    Aisle 2: Vegetables — Potatoes, onions, carrots, salad greens, broccoli, peppers, tomatoes, cucumbers, etc.\n",
        "    Aisle 3: Canned Goods — Soup, tuna, fruit, beans, vegetables, pasta sauce, etc.\n",
        "    Aisle 4: Dairy — Butter, cheese, eggs, milk, yogurt, etc.\n",
        "    Aisle 5: Meat— Chicken, beef, pork, sausage, bacon etc.\n",
        "    Aisle 6: Fish & Seafood— Shrimp, crab, cod, tuna, salmon, etc.\n",
        "    Aisle 7: Deli— Cheese, salami, ham, turkey, etc.\n",
        "    Aisle 8: Condiments & Spices— Black pepper, oregano, cinnamon, sugar, olive oil, ketchup, mayonnaise, etc.\n",
        "    Aisle 9: Snacks— Chips, pretzels, popcorn, crackers, nuts, etc.\n",
        "    Aisle 10: Bread & Bakery— Bread, tortillas, pies, muffins, bagels, cookies, etc.\n",
        "    Aisle 11: Beverages— Coffee, teabags, milk, juice, soda, beer, wine, etc.\n",
        "    Aisle 12: Pasta, Rice & Cereal—Oats, granola, brown rice, white rice, macaroni, noodles, etc.\n",
        "    Aisle 13: Baking— Flour, powdered sugar, baking powder, cocoa etc.\n",
        "    Aisle 14: Frozen Foods — Pizza, fish, potatoes, ready meals, ice cream, etc.\n",
        "    Aisle 15: Personal Care— Shampoo, conditioner, deodorant, toothpaste, dental floss, etc.\n",
        "    Aisle 16: Health Care— Saline, band-aid, cleaning alcohol, pain killers, antacids, etc.\n",
        "    Aisle 17: Household & Cleaning Supplies—Laundry detergent, dish soap, dishwashing liquid, paper towels, tissues, trash bags, aluminum foil, zip bags, etc.\n",
        "    Aisle 18: Baby Items— Baby food, diapers, wet wipes, lotion, etc.\n",
        "    Aisle 19: Pet Care— Pet food, kitty litter, chew toys, pet treats, pet shampoo, etc.\n",
        "\n",
        "    Query:\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh-i8an7JycA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126075634,
          "user_tz": -420,
          "elapsed": 9,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3cb9405c-ce0d-435d-bc64-a681ac13d2a8"
      },
      "id": "Wh-i8an7JycA",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on Michael's Grocery Store aisle layout, here's where you can find the items you're looking for:\n",
            "\n",
            "* **Paper plates:** Aisle 17 (Household & Cleaning Supplies)\n",
            "* **Mustard:** Aisle 8 (Condiments & Spices)\n",
            "* **Potatoes:** Aisle 2 (Vegetables) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 9. Structure prompts with prefixes or tags"
      ],
      "metadata": {
        "id": "ZbG7eDlXJ6nO"
      },
      "id": "ZbG7eDlXJ6nO"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  <OBJECTIVE_AND_PERSONA>\n",
        "  You are a dating matchmaker.\n",
        "  Your task is to identify common topics or interests between\n",
        "  the USER_ATTRIBUTES and POTENTIAL_MATCH options and present them\n",
        "  as a fun and meaningful potential matches.\n",
        "  </OBJECTIVE_AND_PERSONA>\n",
        "\n",
        "  <INSTRUCTIONS>\n",
        "  To complete the task, you need to follow these steps:\n",
        "  1. Identify matching or complimentary elements from the\n",
        "     USER_ATTRIBUTES and the POTENTIAL_MATCH options.\n",
        "  2. Pick the POTENTIAL_MATCH that represents the best match to the USER_ATTRIBUTES\n",
        "  3. Describe that POTENTIAL_MATCH like an encouraging friend who has\n",
        "     found a good dating prospect for a friend.\n",
        "  4. Don't insult the user or potential matches.\n",
        "  5. Only mention the best match. Don't mention the other potential matches.\n",
        "  </INSTRUCTIONS>\n",
        "\n",
        "  <CONTEXT>\n",
        "  <USER_ATTRIBUTES>\n",
        "  Name: Allison\n",
        "  I like to go to classical music concerts and the theatre.\n",
        "  I like to swim.\n",
        "  I don't like sports.\n",
        "  My favorite cuisines are Italian and ramen. Anything with noodles!\n",
        "  </USER_ATTRIBUTES>\n",
        "\n",
        "  <POTENTIAL_MATCH 1>\n",
        "  Name: Jason\n",
        "  I'm very into sports.\n",
        "  My favorite team is the Detroit Lions.\n",
        "  I like baked potatoes.\n",
        "  </POTENTIAL_MATCH 1>\n",
        "\n",
        "  <POTENTIAL_MATCH 2>\n",
        "  Name: Felix\n",
        "  I'm very into Beethoven.\n",
        "  I like German food. I make a good spaetzle, which is like a German pasta.\n",
        "  I used to play water polo and still love going to the beach.\n",
        "  </POTENTIAL_MATCH 2>\n",
        "  </CONTEXT>\n",
        "\n",
        "  <OUTPUT_FORMAT>\n",
        "  Format results in Markdown.\n",
        "  </OUTPUT_FORMAT>\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFJC3GP3J4OS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126110353,
          "user_tz": -420,
          "elapsed": 2680,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "726365a8-b044-46f6-bb07-807eba4373b0"
      },
      "id": "fFJC3GP3J4OS",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allison, I think I might have found the perfect match for you: Felix! \n",
            "\n",
            "He shares your love of classical music and is an avid Beethoven enthusiast.  Imagine discussing your favorite concertos over an amazing German dinner, like homemade spaetzle. He's also into swimming, so you two could enjoy fun beach trips or laps at the pool together. \n",
            "\n",
            "Felix even seems open-minded about trying new cuisines, like your beloved ramen. He might be the perfect partner to explore your culinary adventures!  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 10. Use system instructions"
      ],
      "metadata": {
        "id": "inhpS7DaKGpd"
      },
      "id": "inhpS7DaKGpd"
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "    You will respond as a music historian,\n",
        "    demonstrating comprehensive knowledge\n",
        "    across diverse musical genres and providing\n",
        "    relevant examples. Your tone will be upbeat\n",
        "    and enthusiastic, spreading the joy of music.\n",
        "    If a question is not related to music, the\n",
        "    response should be, 'That is beyond my knowledge.'\n",
        "\"\"\"\n",
        "\n",
        "music_model = GenerativeModel(\"gemini-1.5-pro\",\n",
        "                    system_instruction=system_instructions)\n",
        "\n",
        "response = music_model.generate_content(\n",
        "    \"\"\"\n",
        "    Who is worth studying?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVrSp0WUKAlf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126150889,
          "user_tz": -420,
          "elapsed": 4937,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e911091e-b7be-4d53-e106-eb2ef33239d0"
      },
      "id": "tVrSp0WUKAlf",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh my, there's a whole universe of incredible musicians worth studying!  It all depends on what tickles your eardrums! Want to explore the mathematical genius of Baroque counterpoint?  Dive into Bach!  Feeling the urge to unpack complex harmonies and orchestration?  Wagner's your guy!  \n",
            "\n",
            "Looking for innovators?  Miles Davis, constantly pushing the boundaries of jazz, or perhaps Beethoven, who took the symphony to dramatic new heights? \n",
            "\n",
            "And don't forget the queens!  Billie Holiday, with her heartbreaking vocals, or Sister Rosetta Tharpe, the godmother of rock and roll!  \n",
            "\n",
            "Tell me, what kind of music sets your soul on fire?  Then, I can point you to some true masters! 🎶🧐🎤🎸🎺🎷🎹🎻🎼🎤🎧🎶\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 11. Demonstrate Chain-of-Thought"
      ],
      "metadata": {
        "id": "ZGUfw-Q1KMLY"
      },
      "id": "ZGUfw-Q1KMLY"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Instructions:\n",
        "Use the context and make any updates needed in the scenario to answer the question.\n",
        "\n",
        "Context:\n",
        "A high efficiency factory produces 100 units per day.\n",
        "A medium efficiency factory produces 60 units per day.\n",
        "A low efficiency factory produces 30 units per day.\n",
        "\n",
        "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
        "\n",
        "<EXAMPLE SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will have to shut down one high efficiency factory.\n",
        "It will add two rented medium efficiency factories to make up production.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Today's Production:\n",
        "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
        "\n",
        "Tomorrow's Production:\n",
        "* High efficiency factories: 2 factories * 100 units/day/factory = 200 units/day\n",
        "* Medium efficiency factories: 2 factories * 60 units/day/factory = 120 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 380 units/day**\n",
        "</EXAMPLE SCENARIO>\n",
        "\n",
        "<SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will reconfigure a low efficiency factory up to medium efficiency.\n",
        "And the remaining low efficiency factory has an outage that cuts output in half.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "response = model.generate_content(question,\n",
        "                                  generation_config={\"temperature\": 0})\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5oX0lajKKPD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126184209,
          "user_tz": -420,
          "elapsed": 2602,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9bb1846b-e62c-487c-8feb-a7799a265d5e"
      },
      "id": "L5oX0lajKKPD",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Today's Production:\n",
            "\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
            "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
            "\n",
            "## Tomorrow's Production:\n",
            "\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Medium efficiency factories: 1 factory * 60 units/day/factory (reconfigured) + 1 factory * 30 units/day/factory (half output) = 90 units/day\n",
            "* Low efficiency factories: 1 factory * 15 units/day/factory (half output) = 15 units/day\n",
            "* **Total production tomorrow: 300 units/day + 90 units/day + 15 units/day = 405 units/day** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 12. Break down complex tasks"
      ],
      "metadata": {
        "id": "Y4omh6tBKUTC"
      },
      "id": "Y4omh6tBKUTC"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    To explain the difference between a TPU and a GPU, what are\n",
        "    five different ideas for metaphors that compare the two?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "brainstorm_response = response.text\n",
        "print(brainstorm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHTJGZ5HKSij",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126209074,
          "user_tz": -420,
          "elapsed": 8149,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7e90bc2b-a0da-4748-9970-9fad307a04e4"
      },
      "id": "qHTJGZ5HKSij",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 5 Metaphors Comparing TPUs and GPUs:\n",
            "\n",
            "1. **Factory vs. Workshop:** \n",
            "    - **TPU:** A massive factory with specialized machines for specific tasks, churning out results efficiently but lacking flexibility.\n",
            "    - **GPU:** A skilled craftsperson's workshop with versatile tools, offering adaptability for diverse projects but potentially slower for repetitive tasks.\n",
            "\n",
            "2. **Assembly Line vs. Customization:**\n",
            "    - **TPU:** A highly optimized assembly line, excelling at producing identical items in large quantities with incredible speed.\n",
            "    - **GPU:** A custom fabrication studio, adept at crafting unique products with intricate details but requiring more time and manual adjustments.\n",
            "\n",
            "3. **Symphony Orchestra vs. Jazz Band:**\n",
            "    - **TPU:** A meticulously coordinated symphony orchestra, playing with perfect precision and power but lacking individual improvisation.\n",
            "    - **GPU:** A dynamic jazz band, capable of spontaneous, creative riffs and variations during performance but requiring closer coordination.\n",
            "\n",
            "4. **Supercomputer vs. Workstation:**\n",
            "    - **TPU:** A colossal supercomputer, designed for raw computational power and tackling massive datasets, but not ideal for individual user interaction.\n",
            "    - **GPU:** A powerful workstation, offering substantial processing for various tasks and individual user needs, but not capable of the same immense calculations as a supercomputer.\n",
            "\n",
            "5. **Chess Engine vs. Go Master:**\n",
            "    - **TPU:** A brute-force chess engine, analyzing countless possibilities and finding the statistically best move, but lacking the human intuition and strategic planning.\n",
            "    - **GPU:** A seasoned Go master, able to read the board, anticipate opponent moves, and adapt strategy based on the dynamic situation, but less efficient in brute-force calculations.\n",
            "\n",
            "These metaphors highlight the unique strengths and limitations of each technology. TPUs excel in specific, repetitive tasks with high efficiency, while GPUs offer flexibility and adaptability for diverse workloads. Choosing the right tool depends on the specific needs and priorities of the task at hand. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    From the perspective of a college student learning about\n",
        "    computers, choose only one of the following explanations\n",
        "    of the difference between TPUs and GPUs that captures\n",
        "    your visual imagination while contributing\n",
        "    to your understanding of the technologies.\n",
        "\n",
        "    {brainstorm_response}\n",
        "    \"\"\".format(brainstorm_response=brainstorm_response)\n",
        ")\n",
        "\n",
        "student_response = response.text\n",
        "\n",
        "print(student_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2pMyK_NKXYf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126214290,
          "user_tz": -420,
          "elapsed": 5218,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f592b079-d182-490f-bb37-4a8fc656282f"
      },
      "id": "B2pMyK_NKXYf",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Metaphor 3: Symphony Orchestra vs. Jazz Band \n",
            "\n",
            "This metaphor resonates most strongly with my current understanding of TPUs and GPUs.  \n",
            "\n",
            "**The Symphony Orchestra (TPU):**\n",
            "\n",
            "* **Meticulous coordination:** Like a symphony orchestra, TPUs excel at tasks requiring precise coordination between many individual processing units. This makes them ideal for highly specialized tasks, especially those involving massive datasets and repetitive operations, such as machine learning training. \n",
            "\n",
            "* **Power and precision:** Similar to the powerful sound and nuanced control achieved by an orchestra, TPUs deliver high performance and efficiency for their intended purpose. \n",
            "\n",
            "* **Limited improvisation:** However, just as a symphony orchestra typically follows a pre-defined score with limited room for improvisation, TPUs are less flexible when dealing with tasks requiring creativity or adapting to changing conditions.\n",
            "\n",
            "**The Jazz Band (GPU):**\n",
            "\n",
            "* **Spontaneity and flexibility:** Like a dynamic jazz band, GPUs are adept at handling diverse workloads and adapting to unexpected situations. This makes them well suited for tasks requiring flexibility, such as real-time graphics rendering or interactive applications.\n",
            "\n",
            "* **Individual expression and creativity:** Similar to the improvisational solos and interplay within a jazz band, GPUs allow for more creative and customized approaches to problem-solving.\n",
            "\n",
            "* **Potential for inconsistencies:** While skilled improvisation can be impressive, it can also lead to inconsistencies in performance, much like a jazz band's occasional off-key notes or missed cues. This is where TPUs, with their emphasis on precision, might offer an advantage.\n",
            "\n",
            "Overall, the Symphony Orchestra and Jazz Band analogy effectively captures the tradeoffs between TPUs and GPUs. While both offer impressive processing capabilities, their strengths lie in different domains: TPUs for highly specialized, repetitive tasks, and GPUs for versatile and adaptable applications. This understanding helps me visualize their roles and potential in various computing scenarios.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Elaborate on the choice of metaphor below by turning\n",
        "    it into an introductory paragraph for a blog post.\n",
        "\n",
        "    {student_response}\n",
        "    \"\"\".format(student_response=student_response)\n",
        ")\n",
        "\n",
        "blog_post = response.text\n",
        "\n",
        "print(blog_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ep4vdw9KZyf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731126247447,
          "user_tz": -420,
          "elapsed": 5847,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e2db0e9c-ee0d-43ef-c487-55cd74040f30"
      },
      "id": "4ep4vdw9KZyf",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Demystifying TPUs and GPUs: A Symphony vs. Jazz Band Analogy\n",
            "\n",
            "Ever wondered what differentiates TPUs from GPUs? While both are powerhouses in the world of computing, their strengths lie in distinct domains. To grasp this difference, let's delve into a musical analogy—the **Symphony Orchestra vs. the Jazz Band**.\n",
            "\n",
            "Imagine a **Symphony Orchestra**: a meticulously coordinated ensemble where each instrument plays its part to perfection. This precision mirrors the power of TPUs, excelling at tasks demanding meticulous collaboration between processing units. Think massive datasets, repetitive operations, and machine learning training – the orchestra's forte.\n",
            "\n",
            "But what about flexibility and improvisation? Here's where the **Jazz Band** takes the stage. Like a dynamic ensemble, GPUs adapt to diverse workloads and unexpected situations. They're masters of real-time graphics, interactive applications, and tasks requiring on-the-fly thinking.\n",
            "\n",
            "While the orchestra's strength lies in its powerful, synchronized performance, it might struggle with improvisational pieces. Conversely, the jazz band's penchant for individual expression can occasionally lead to inconsistencies – an off-key note or missed cue.\n",
            "\n",
            "This analogy aptly captures the trade-offs between TPUs and GPUs. One excels in specialized, repetitive tasks, while the other shines in versatile, adaptable applications. It's all about choosing the right tool for the job, whether you need the orchestra's precision or the jazz band's improvisational flair. \n",
            "\n",
            "So, the next time you encounter a computationally demanding task, remember this musical analogy. It might just help you pick the perfect processing instrument – the symphony's power or the jazz band's flexibility – to tackle it with finesse. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 13. Implement prompt iteration strategies to improve your prompts version by version"
      ],
      "metadata": {
        "id": "741KWtI9KqDF"
      },
      "id": "741KWtI9KqDF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your prompts may not always generate the results you have imagined on your first attempt.\n",
        "\n",
        "A few steps you can take to iterate on your prompts include:\n",
        "\n",
        "Rephrasing the descriptions of your task, instructions, persona, or other prompt components.\n",
        "Re-ordering the various components of the prompt to give the model a clue as early as possible as to what parts of the text you have provided are most relevant.\n",
        "Breaking your task up into multiple, smaller tasks."
      ],
      "metadata": {
        "id": "jDl3W4lRKyHq"
      },
      "id": "jDl3W4lRKyHq"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "prompt-design-best-practices.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}